{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uua1wvw7iQB4"
   },
   "source": [
    "![](logo1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMnWC3LuifEi"
   },
   "source": [
    "# **shAI Training 2023 | Level 1**\n",
    "\n",
    "## Task #8 (End-to-End ML Project {part_2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rbe_ZnKi-uY"
   },
   "source": [
    "## Welcome to the exercises for reviewing second part of end to end ML project.\n",
    "**Make sure that you read and understand ch2 from the hands-on ML book (page 72 to the end of the chapter ) before start with this notebook.**\n",
    "\n",
    "**If you stuck with anything reread that part from the book and feel free to ask about anything in the messenger group as you go along.**\n",
    "\n",
    " ## Good Luck : )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAbRZ0fwfOb4"
   },
   "source": [
    "## first run the following cell for the first part of the project to continue your work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Q3v160SJfL7U"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ObbhNRgSfu6_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "   csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "   return pd.read_csv(csv_path)\n",
    "   \n",
    "fetch_housing_data()\n",
    "housing = load_housing_data()\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = [\n",
    "    list(housing.columns).index(col)\n",
    "    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "        \n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "housing = train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = train_set[\"median_house_value\"].copy()\n",
    "\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    " ('imputer', SimpleImputer(strategy=\"median\")),\n",
    " ('attribs_adder', CombinedAttributesAdder()),\n",
    " ('std_scaler', StandardScaler())])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    " (\"num\", num_pipeline, num_attribs),\n",
    " (\"cat\", OneHotEncoder(), cat_attribs)])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa6vPfm6jxsF"
   },
   "source": [
    "# 1- Select and Train a Model\n",
    "\n",
    "# Let’s first train a LinearRegression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JCl0ZYDRjGz_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "# Initializing a Linear Regression model\n",
    "lin_reg = LinearRegression()\n",
    "# Fitting the model to the prepared housing data\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nDxOY7GmTNc"
   },
   "source": [
    "# First try it out on a few instances from the training set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7Lx7VQm7pwSQ"
   },
   "outputs": [],
   "source": [
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BU-ynaaIpYHO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [181746.54359616 290558.74973505 244957.50017771 146498.51061398\n",
      " 163230.42393939]\n",
      "Actual Labels: [103000.0, 382100.0, 172600.0, 93400.0, 96500.0]\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "# Transforming the new instances using the full pipeline\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "# Using the trained linear regression model to make predictions\n",
    "predictions = lin_reg.predict(some_data_prepared)\n",
    "# Printing the predictions\n",
    "print(\"Predictions:\", predictions)\n",
    "# Printing the actual labels\n",
    "print(\"Actual Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjmwxoU-qFnb"
   },
   "source": [
    "# measure this regression model’s RMSE on the whole training set \n",
    "* sing Scikit-Learn’s mean_squared_error() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rczx22dFqRMc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "aCYZh9ExqWMJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the whole training set: 67593.20745775253\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "# Making predictions on the whole training set\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "# Calculating RMSE\n",
    "mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE on the whole training set:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLsKfuQpcfyx"
   },
   "source": [
    "# judge on the RMSE result for this model \n",
    "write down your answar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnBVcR-MeFqa"
   },
   "source": [
    "An RMSE (Root Mean Squared Error) of approximately 67593.21 on the whole training set means that, on average, the model's predictions are off by around $67,593.21 when compared to the actual median house values in the training set.An RMSE of $67,593.21 suggests that the model's performance may not be satisfactory and further investigation, feature engineering, or model selection may be necessary to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vImNak3CqqFo"
   },
   "source": [
    "# Let’s train a Decision Tree Regressor model \n",
    "## more powerful model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8syfCBveqY2q"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vrUPZzBhq-do"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "# Initializing Decision Tree Regressor model\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "# Fitting the model to the prepared housing data\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRhxYj0Aq9op"
   },
   "source": [
    "# Now evaluate the model on the training set \n",
    "* using Scikit-Learn’s mean_squared_error() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DYCxUSCkrNIY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the whole training set (Decision Tree Regressor): 0.0\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "# Making predictions on the training set\n",
    "housing_predictions_tree = tree_reg.predict(housing_prepared)\n",
    "\n",
    "# Calculating RMSE\n",
    "mse_tree = mean_squared_error(housing_labels, housing_predictions_tree)\n",
    "rmse_tree = np.sqrt(mse_tree)\n",
    "print(\"RMSE on the whole training set (Decision Tree Regressor):\", rmse_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSxXI9b8iZPs"
   },
   "source": [
    "# Explaine this result \n",
    "write down your answar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVSMQ7kbiZSi"
   },
   "source": [
    "This perfect fit could be due to several reasons:\n",
    "\n",
    "1) Overfitting: Decision Trees are prone to overfitting, especially if they are allowed to grow without any constraints. In this case, the model might have memorized the training data's noise and outliers, leading to perfect performance on the training set but poor generalization to unseen data.\n",
    "2) Hyperparameters: The default hyperparameters of the DecisionTreeRegressor might not have been tuned to prevent overfitting. Setting constraints on the maximum depth of the tree, minimum samples per leaf, or maximum number of leaf nodes could help in preventing overfitting.\n",
    "3) Data Characteristics: It's also possible that the dataset itself is relatively simple or small, making it easier for the Decision Tree model to fit the data perfectly.\n",
    "4) Preprocessing: If the data preprocessing steps used before training the model were incorrect or inadequate, it could lead to misleading results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rj7b4zSPrdyH"
   },
   "source": [
    "# Evaluation Using Cross-Validation\n",
    "\n",
    "1-split the training set into 10 distinct subsets then train and evaluate the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "JmNrgsBrwIe3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yXNPsWjcwMd_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores for each fold:\n",
      "Fold 1: 65312.860440308985\n",
      "Fold 2: 70581.6986567638\n",
      "Fold 3: 67849.75809964613\n",
      "Fold 4: 71460.33789358212\n",
      "Fold 5: 74035.29744573774\n",
      "Fold 6: 65562.42978503302\n",
      "Fold 7: 67964.10942543222\n",
      "Fold 8: 69102.89388457107\n",
      "Fold 9: 66876.66473025372\n",
      "Fold 10: 69735.84760006213\n",
      "\n",
      "Mean RMSE: 68848.18979613911\n",
      "Standard deviation of RMSE: 2579.6785558576307\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "# Defining the Decision Tree Regressor model\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Performing 10-fold cross-validation\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "# Calculating RMSE scores\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "# Displaying the RMSE scores for each fold\n",
    "print(\"RMSE scores for each fold:\")\n",
    "for i, rmse in enumerate(rmse_scores):\n",
    "    print(f\"Fold {i+1}: {rmse}\")\n",
    "\n",
    "# Calculating and display the mean and standard deviation of RMSE scores\n",
    "print(\"\\nMean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqReIY3urLP8"
   },
   "source": [
    "2- display the resultant scores and calculate its Mean and Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1g8jIq-6raVF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores for each fold:\n",
      "Fold 1: 65312.860440308985\n",
      "Fold 2: 70581.6986567638\n",
      "Fold 3: 67849.75809964613\n",
      "Fold 4: 71460.33789358212\n",
      "Fold 5: 74035.29744573774\n",
      "Fold 6: 65562.42978503302\n",
      "Fold 7: 67964.10942543222\n",
      "Fold 8: 69102.89388457107\n",
      "Fold 9: 66876.66473025372\n",
      "Fold 10: 69735.84760006213\n",
      "\n",
      "Mean RMSE: 68848.18979613911\n",
      "Standard deviation of RMSE: 2579.6785558576307\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "# Displaying the RMSE scores for each fold\n",
    "print(\"RMSE scores for each fold:\")\n",
    "for i, rmse in enumerate(rmse_scores):\n",
    "    print(f\"Fold {i+1}: {rmse}\")\n",
    "# Calculating and display the mean and standard deviation of RMSE scores\n",
    "mean_rmse = rmse_scores.mean()\n",
    "std_rmse = rmse_scores.std()\n",
    "print(\"\\nMean RMSE:\", mean_rmse)\n",
    "print(\"Standard deviation of RMSE:\", std_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6paGk_hsGGY"
   },
   "source": [
    "3-repaet the same steps to compute the same scores for the Linear Regression  model \n",
    "\n",
    "*notice the difference between the results of the two models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ol3C6DmusWfx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores for each fold (Linear Regression):\n",
      "Fold 1: 65000.67382615272\n",
      "Fold 2: 70960.56056304109\n",
      "Fold 3: 67122.6393512386\n",
      "Fold 4: 66089.6315386527\n",
      "Fold 5: 68402.54686442243\n",
      "Fold 6: 65266.34735287604\n",
      "Fold 7: 65218.78174480775\n",
      "Fold 8: 68525.46981753556\n",
      "Fold 9: 72739.87555995534\n",
      "Fold 10: 68957.34111905852\n",
      "\n",
      "Mean RMSE (Linear Regression): 67828.38677377408\n",
      "Standard deviation of RMSE (Linear Regression): 2468.0913950652257\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Performing 10-fold cross-validation\n",
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "# Calculating RMSE scores\n",
    "rmse_lin_scores = np.sqrt(-lin_scores)\n",
    "\n",
    "# Displaying the RMSE scores for each fold\n",
    "print(\"RMSE scores for each fold (Linear Regression):\")\n",
    "for i, rmse in enumerate(rmse_lin_scores):\n",
    "    print(f\"Fold {i+1}: {rmse}\")\n",
    "\n",
    "# Calculating and display the mean and standard deviation of RMSE scores\n",
    "mean_rmse_lin = rmse_lin_scores.mean()\n",
    "std_rmse_lin = rmse_lin_scores.std()\n",
    "print(\"\\nMean RMSE (Linear Regression):\", mean_rmse_lin)\n",
    "print(\"Standard deviation of RMSE (Linear Regression):\", std_rmse_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdQ85uTEtDy1"
   },
   "source": [
    "## Let’s train one last model the RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "O1PPFq5TtdDP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores for each fold (Random Forest Regressor):\n",
      "Fold 1: 47341.96931396659\n",
      "Fold 2: 51653.53070248334\n",
      "Fold 3: 49360.291488834606\n",
      "Fold 4: 51625.62777032113\n",
      "Fold 5: 52771.91063892273\n",
      "Fold 6: 46989.97118038409\n",
      "Fold 7: 47333.72603397942\n",
      "Fold 8: 50636.24303693077\n",
      "Fold 9: 48951.73251683118\n",
      "Fold 10: 50183.60590465184\n",
      "\n",
      "Mean RMSE (Random Forest Regressor): 49684.86085873057\n",
      "Standard deviation of RMSE (Random Forest Regressor): 1929.9797084102233\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "# Defining the RandomForestRegressor model\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Performing 10-fold cross-validation\n",
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                                 scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "# Calculating RMSE scores\n",
    "rmse_forest_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "# Displaying the RMSE scores for each fold\n",
    "print(\"RMSE scores for each fold (Random Forest Regressor):\")\n",
    "for i, rmse in enumerate(rmse_forest_scores):\n",
    "    print(f\"Fold {i+1}: {rmse}\")\n",
    "\n",
    "# Calculating and display the mean and standard deviation of RMSE scores\n",
    "mean_rmse_forest = rmse_forest_scores.mean()\n",
    "std_rmse_forest = rmse_forest_scores.std()\n",
    "print(\"\\nMean RMSE (Random Forest Regressor):\", mean_rmse_forest)\n",
    "print(\"Standard deviation of RMSE (Random Forest Regressor):\", std_rmse_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSxaBthCtw93"
   },
   "source": [
    "# repeat the same steps to compute the same scores its Mean and Standard deviation for the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAc2MOQwt2lC"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Defining the RandomForestRegressor model\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Performing 10-fold cross-validation\n",
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "# Calculating RMSE scores\n",
    "rmse_forest_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "# Displaying the RMSE scores for each fold\n",
    "print(\"RMSE scores for each fold (Random Forest Regressor):\")\n",
    "for i, rmse in enumerate(rmse_forest_scores):\n",
    "    print(f\"Fold {i+1}: {rmse}\")\n",
    "\n",
    "# Calculating and display the mean and standard deviation of RMSE scores\n",
    "mean_rmse_forest = rmse_forest_scores.mean()\n",
    "std_rmse_forest = rmse_forest_scores.std()\n",
    "print(\"\\nMean RMSE (Random Forest Regressor):\", mean_rmse_forest)\n",
    "print(\"Standard deviation of RMSE (Random Forest Regressor):\", std_rmse_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn2u9DOxvE5S"
   },
   "source": [
    "# Save every model you experiment with \n",
    "*using the joblib library*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWyIi3mtva85"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Saving the Decision Tree Regressor model\n",
    "dump(tree_reg, 'decision_tree_model.joblib')\n",
    "\n",
    "# Saving the Linear Regression model\n",
    "dump(lin_reg, 'linear_regression_model.joblib')\n",
    "\n",
    "# Saving the Random Forest Regressor model\n",
    "dump(forest_reg, 'random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIC6O-h0wOBJ"
   },
   "source": [
    "## now you have a shortlist of promising models. You now need to\n",
    "## fine-tune them!\n",
    "# Fine-Tune Your Model\n",
    "\n",
    "## 1- Grid Search\n",
    "## evaluate all the possible combinations of hyperparameter values for the RandomForestRegressor \n",
    "*It may take a long time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8Wqd-Pix3Sm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-zNvGLhyGGb"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Defining the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at each leaf node\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Defining the RandomForestRegressor model\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Performing grid search with cross-validation\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "# Fitting the grid search to the data\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# Getting the best hyperparameters found\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Getting the best estimator (model)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluating the best model\n",
    "cv_results = grid_search.cv_results_\n",
    "for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhYbsAnE0j75"
   },
   "source": [
    "with the evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhDCrx0Y0ocN"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Getting the evaluation scores for all combinations of hyperparameters\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Printing the evaluation scores for each combination of hyperparameters\n",
    "for mean_score, std_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"std_test_score\"], cv_results[\"params\"]):\n",
    "    print(f\"Mean RMSE: {np.sqrt(-mean_score):.2f} (Std: {std_score:.2f}) for {params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjRCrlqEyH1A"
   },
   "source": [
    "# Analyze the Best Models and Their Errors\n",
    "1-indicate the relative importance of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2MkCD1Byh9F"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Get the feature importances\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Get the list of feature names\n",
    "feature_names = list(full_pipeline.named_transformers_['num'].get_feature_names_out()) + ['rooms_per_household', 'population_per_household', 'bedrooms_per_room']\n",
    "\n",
    "# Pair the feature names with their importances and sort them\n",
    "feature_importances_dict = dict(zip(feature_names, feature_importances))\n",
    "sorted_feature_importances = sorted(feature_importances_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the relative importance of each attribute\n",
    "print(\"Relative Importance of Each Attribute:\")\n",
    "for feature, importance in sorted_feature_importances:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b01L7mUm1xTV"
   },
   "source": [
    "2-display these importance scores next to their corresponding attribute names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dau43zXt14i7"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Printing the attribute names and their importance scores\n",
    "print(\"Attribute Name: Importance Score\")\n",
    "for feature, importance in sorted_feature_importances:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esOPiD6Pyice"
   },
   "source": [
    "## Now is the time to evaluate the final model on the test set.\n",
    "# Evaluate Your System on the Test Set\n",
    "\n",
    "1-get the predictors and the labels from your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrmGwOEyykad"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Separating the predictors (features) from the labels in the test set\n",
    "X_test = test_set.drop(\"median_house_value\", axis=1)  # predictors\n",
    "y_test = test_set[\"median_house_value\"].copy()  # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhkKu23G2yNd"
   },
   "source": [
    "2-run your full_pipeline to transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBfW1WG823TE"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Transforming the test set using the full_pipeline\n",
    "X_test_prepared = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNVnMSJy28xt"
   },
   "source": [
    "3-evaluate the final model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrcgAUoy2_tc"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Making predictions on the transformed test data using the trained model\n",
    "final_predictions = best_model.predict(X_test_prepared)\n",
    "\n",
    "# Calculating RMSE to evaluate the performance of the final model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(\"Final RMSE on the test set:\", final_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYBxgnsx3Ipr"
   },
   "source": [
    "# compute a 95% confidence interval for the generalization error \n",
    "*using scipy.stats.t.interval():*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngWpgPrE3NaS"
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RFaMou83WBY"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Defining the degrees of freedom\n",
    "degrees_of_freedom = len(y_test) - 1\n",
    "\n",
    "# Computing the standard error of the mean squared error\n",
    "standard_error = np.sqrt(final_mse / len(y_test))\n",
    "\n",
    "# Computing the margin of error for a 95% confidence interval\n",
    "margin_of_error = stats.t.ppf(0.975, df=degrees_of_freedom) * standard_error\n",
    "\n",
    "# Computing the lower and upper bounds of the confidence interval\n",
    "lower_bound = final_rmse - margin_of_error\n",
    "upper_bound = final_rmse + margin_of_error\n",
    "\n",
    "print(\"95% Confidence Interval for Generalization Error:\")\n",
    "print(f\"Lower Bound: {lower_bound:.2f}\")\n",
    "print(f\"Upper Bound: {upper_bound:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTsy6N8Uytpo"
   },
   "source": [
    "# Great Job!\n",
    "# #shAI_Club"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
